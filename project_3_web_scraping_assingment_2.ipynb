{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-1 :Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name,experience_required. You have to scrape first 10 jobs data.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries to perform web_scraping\n",
    "#!pip install BeautifulSoup4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries to perform web_scraping\n",
    "import selenium \n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to web driver\n",
    "driver=webdriver.Chrome(r\"C:/Users/Akshai/Downloads/chromedriver_win32 (1)/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying the url of the webpage which we want to scarpe\n",
    "url=\"https://www.naukri.com/data-analyst-jobs-in-banglore?k=data%20analyst&l=banglore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the web driver using the web_driver\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_titles=[]\n",
    "Job_Locations=[]\n",
    "Company_name=[]\n",
    "experince_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the Job title web element from the webpage\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"1e0a3a3b-4655-4d2e-8efa-d00570e9d221\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"f7b92c44-fd41-4d6b-abd1-9b7f7f8a1773\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"f2ebfc44-f205-4d62-9f58-0bd78c7fa77d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"e4118245-127d-4a45-9f58-849f043cb246\")>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the first 10 jobs title \n",
    "n_titles=titles[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we have saved the web element above from which we want to scrape the job title\n",
    "\n",
    "#implementing the loop to the web element extracted above and taking out the text present in it\n",
    "for i in n_titles:\n",
    "    title=i.text\n",
    "    Job_titles.append(title)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Immediate opening For Data Scientist/Data Analyst',\n",
       " 'Hiring Data Analysts',\n",
       " 'Hiring Data Analysts',\n",
       " 'Data Analyst',\n",
       " 'Business Data Analyst',\n",
       " 'Data Analyst ( Predictive Modelling)',\n",
       " 'Data Scientist / Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'NiFi Data Analyst',\n",
       " 'NiFi Data Analyst']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking wether the job title extracted above is correct or not\n",
    "Job_titles[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the Location web element from the webpage\n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"7d592f27-15f6-4fda-afe4-a31106569e66\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"7a90391b-f413-4f1e-9176-e6be8a0a8e8a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"c6b1785d-4d36-470e-9029-3488f8380204\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"92480b9f-55ae-45f5-a247-2fb2f59c2b5b\")>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the first 10 jobs location title \n",
    "n_location=location[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we have saved the web element above from which we want to scrape the job Location\n",
    "\n",
    "#implementing the loop to the web element extracted above and taking out the text present in it\n",
    "for i in n_location:\n",
    "    locate=i.text\n",
    "    Job_Locations.append(locate)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chennai, Pune, Bengaluru, Hyderabad',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru',\n",
       " 'Pune, Delhi, Mumbai, Bengaluru, Hyderabad',\n",
       " 'Bengaluru',\n",
       " 'Bengaluru']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_Locations[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the Comapny_Name web element from the webpage\n",
    "co_name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"b67e70ca-10e4-47db-9989-518ed563eaf0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"5c2fd2bd-ac16-489f-b341-3c533a47dfda\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"914f600f-9eba-4793-9de3-662cb6382f43\")>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_name[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the first 10 Company name \n",
    "n_name=co_name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we have saved the web element above from which we want to scrape the Company name\n",
    "\n",
    "#implementing the loop to the web element extracted above and taking out the text present in it\n",
    "for i in n_name:\n",
    "    name_=i.text\n",
    "    Company_name.append(name_)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the Experience web element from the webpage\n",
    "exp=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"d0d2f8aa-1f83-4da8-99bb-1cc2fcd0c6bd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"4405c2ce-4f07-4899-8ae7-64ba2c28f442\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"8dbe8ef316333ae31f17c5fe825f9a29\", element=\"fe526214-02ca-4f8a-9ed8-94bce0e3d022\")>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the first 10 Experince list\n",
    "n_exp=exp[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we have saved the web element above from which we want to scrape the Experience\n",
    "\n",
    "#implementing the loop to the web element extracted above and taking out the text present in it\n",
    "for i in n_exp:\n",
    "    exp_=i.text\n",
    "    experince_list.append(exp_)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crating a dataframe to store Job details\n",
    "Naukari_df=pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the job details in data frame\n",
    "Naukari_df['Company_name']=Company_name\n",
    "Naukari_df['Job_titles']=Job_titles\n",
    "Naukari_df['Loaction']=Job_Locations\n",
    "Naukari_df['Experience']=experince_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job_titles</th>\n",
       "      <th>Loaction</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Immediate opening For Data Scientist/Data Analyst</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Hiring Data Analysts</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Hiring Data Analysts</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cognizant Technology Solutions India Ltd</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>Data Analyst ( Predictive Modelling)</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Altimetrik India Pvt. Ltd</td>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thinkbumblebee Analytics Pvt Ltd</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Pune, Delhi, Mumbai, Bengaluru, Hyderabad</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Capgemini Technology Services India Limited</td>\n",
       "      <td>NiFi Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Capgemini Technology Services India Limited</td>\n",
       "      <td>NiFi Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company_name  \\\n",
       "0  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "1                  Flipkart Internet Private Limited   \n",
       "2                  Flipkart Internet Private Limited   \n",
       "3           Cognizant Technology Solutions India Ltd   \n",
       "4                      GENPACT India Private Limited   \n",
       "5                                       AVE-Promagne   \n",
       "6                          Altimetrik India Pvt. Ltd   \n",
       "7                   Thinkbumblebee Analytics Pvt Ltd   \n",
       "8        Capgemini Technology Services India Limited   \n",
       "9        Capgemini Technology Services India Limited   \n",
       "\n",
       "                                          Job_titles  \\\n",
       "0  Immediate opening For Data Scientist/Data Analyst   \n",
       "1                               Hiring Data Analysts   \n",
       "2                               Hiring Data Analysts   \n",
       "3                                       Data Analyst   \n",
       "4                              Business Data Analyst   \n",
       "5               Data Analyst ( Predictive Modelling)   \n",
       "6                      Data Scientist / Data Analyst   \n",
       "7                                       Data Analyst   \n",
       "8                                  NiFi Data Analyst   \n",
       "9                                  NiFi Data Analyst   \n",
       "\n",
       "                                    Loaction Experience  \n",
       "0        Chennai, Pune, Bengaluru, Hyderabad    0-3 Yrs  \n",
       "1                                  Bengaluru    2-5 Yrs  \n",
       "2                                  Bengaluru    2-5 Yrs  \n",
       "3                                  Bengaluru    2-3 Yrs  \n",
       "4                                  Bengaluru    3-6 Yrs  \n",
       "5                                  Bengaluru    2-5 Yrs  \n",
       "6                                  Bengaluru    3-8 Yrs  \n",
       "7  Pune, Delhi, Mumbai, Bengaluru, Hyderabad    3-6 Yrs  \n",
       "8                                  Bengaluru    4-6 Yrs  \n",
       "9                                  Bengaluru    6-9 Yrs  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Naukari_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-2- Write a python program to scrape data for “Data Scientist” Job position in“Bangalore” location. You have to scrape the job-title, job-location,company_name, full job-description. You have to scrape first 10 jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list.append(\"https://www.naukri.com/job-listings-immediate-opening-for-data-scientist-data-analyst-caia-center-for-artificial-intelligence-advanced-analytics-chennai-pune-bengaluru-bangalore-hyderabad-secunderabad-0-to-3-years-210920000599?src=jobsearchDesk&sid=16071840593591586&xp=1&px=1\")\n",
    "url_list.append(\"https://www.naukri.com/job-listings-lead-data-scientist-machine-learning-data-mining-wrackle-technologies-pvt-ltd-bengaluru-bangalore-6-to-11-years-271120902143?src=jobsearchDesk&sid=16072297070276226&xp=2&px=1\")\n",
    "url_list.append(\"https://www.naukri.com/job-listings-data-scientist-data-analyst-altimetrik-india-pvt-ltd-bengaluru-bangalore-3-to-8-years-261120500590?src=jobsearchDesk&sid=16072297070276226&xp=3&px=1\")\n",
    "url_list.append(\"https://www.naukri.com/job-listings-explore-openings-on-data-scientist-bristlecone-india-limited-pune-mumbai-bengaluru-bangalore-4-to-9-years-141020003338?src=jobsearchDesk&sid=16072297070276226&xp=4&px=1\")\n",
    "url_list.append(\"https://www.naukri.com/job-listings-senior-principal-software-engineer-it-data-scientist-dell-international-services-indiaprivate-limited-bengaluru-bangalore-10-to-15-years-251120902181?src=jobsearchDesk&sid=16072297070276226&xp=5&px=1\")\n",
    "url_list.append(\"https://www.naukri.com/job-listings-senior-data-scientist-philips-lighting-bengaluru-bangalore-6-to-10-years-271120501144?src=jobsearchDesk&sid=16072297070276226&xp=6&px=1\")\n",
    "url_list.append(\"https://www.naukri.com/job-listings-machine-learning-lead-data-scientist-morgan-stanley-advantage-services-pvt-ltd-bengaluru-bangalore-4-to-6-years-251120500011?src=jobsearchDesk&sid=16072297070276226&xp=7&px=1\")\n",
    "url_list.append(\"https://www.naukri.com/job-listings-global-medical-data-scientist-glaxosmithkline-pharmaceuticals-limited-bengaluru-bangalore-5-to-9-years-281120000220?src=jobsearchDesk&sid=16072297070276226&xp=8&px=1\")\n",
    "url_list.append(\"https://www.naukri.com/job-listings-advanced-architect-data-scientist-mphasis-limited-bengaluru-bangalore-12-to-18-years-051220900856?src=jobsearchDesk&sid=16072297070276226&xp=9&px=1\")\n",
    "url_list.append(\"https://www.naukri.com/job-listings-principal-data-scientist-philips-lighting-bengaluru-bangalore-10-to-15-years-021220501156?src=jobsearchDesk&sid=16072297070276226&xp=10&px=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-immediate-opening-for-data-scientist-data-analyst-caia-center-for-artificial-intelligence-advanced-analytics-chennai-pune-bengaluru-bangalore-hyderabad-secunderabad-0-to-3-years-210920000599?src=jobsearchDesk&sid=16071840593591586&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-machine-learning-data-mining-wrackle-technologies-pvt-ltd-bengaluru-bangalore-6-to-11-years-271120902143?src=jobsearchDesk&sid=16072297070276226&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-data-analyst-altimetrik-india-pvt-ltd-bengaluru-bangalore-3-to-8-years-261120500590?src=jobsearchDesk&sid=16072297070276226&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-explore-openings-on-data-scientist-bristlecone-india-limited-pune-mumbai-bengaluru-bangalore-4-to-9-years-141020003338?src=jobsearchDesk&sid=16072297070276226&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-principal-software-engineer-it-data-scientist-dell-international-services-indiaprivate-limited-bengaluru-bangalore-10-to-15-years-251120902181?src=jobsearchDesk&sid=16072297070276226&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-philips-lighting-bengaluru-bangalore-6-to-10-years-271120501144?src=jobsearchDesk&sid=16072297070276226&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-machine-learning-lead-data-scientist-morgan-stanley-advantage-services-pvt-ltd-bengaluru-bangalore-4-to-6-years-251120500011?src=jobsearchDesk&sid=16072297070276226&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-global-medical-data-scientist-glaxosmithkline-pharmaceuticals-limited-bengaluru-bangalore-5-to-9-years-281120000220?src=jobsearchDesk&sid=16072297070276226&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-advanced-architect-data-scientist-mphasis-limited-bengaluru-bangalore-12-to-18-years-051220900856?src=jobsearchDesk&sid=16072297070276226&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-principal-data-scientist-philips-lighting-bengaluru-bangalore-10-to-15-years-021220501156?src=jobsearchDesk&sid=16072297070276226&xp=10&px=1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Job_titles=[]\n",
    "Data_Job_Locations=[]\n",
    "Data_Company_name=[]\n",
    "Data_Job_description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to web driver\n",
    "driver=webdriver.Chrome(r\"C:/Users/Akshai/Downloads/chromedriver_win32 (1)/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immediate opening For Data Scientist/Data Analyst\n",
      "Lead Data Scientist - Machine Learning/ Data Mining\n",
      "Data Scientist / Data Analyst\n",
      "Explore job openings on Data Scientist!!\n",
      "Senior Principal Software Engineer - IT ( Data Scientist )\n",
      "Senior Data Scientist\n",
      "Machine Learning Lead / Data Scientist\n",
      "Principal Data Scientist\n"
     ]
    }
   ],
   "source": [
    "for i in url_list[0:11]:\n",
    "    driver.get(i)\n",
    "    #extracting the Job title web element from the webpage\n",
    "    for j in driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\"):\n",
    "        a=j.text\n",
    "        print(a)\n",
    "        Data_Job_titles.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL MEDICAL DATA SCIENTIST\n",
      "ADVANCED ARCHITECT – DATA SCIENTIST\n"
     ]
    }
   ],
   "source": [
    "#as two of the job title lies in other class extracting them using different loop\n",
    "for i in url_list[0:11]:\n",
    "    driver.get(i)\n",
    "    for k in driver.find_elements_by_xpath(\"//h1[@class='av-special-heading-tag ']\"):\n",
    "        a=k.text\n",
    "        print(a)\n",
    "        Data_Job_titles.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(Data_Job_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chennai, Pune, Bengaluru, Hyderabad\n",
      "Bengaluru\n",
      "Bengaluru\n",
      "Pune, Mumbai, Bengaluru\n",
      "Bengaluru\n",
      "Bengaluru\n",
      "Bengaluru\n",
      "Bengaluru\n"
     ]
    }
   ],
   "source": [
    "#extracting the job Location web element from the webpage\n",
    "for i in url_list[0:11]:\n",
    "    driver.get(i)\n",
    "    for j in driver.find_elements_by_xpath(\"//span[@class='location ']\"):\n",
    "        a=j.text\n",
    "        print(a)\n",
    "        Data_Job_Locations.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bengaluru\n",
      "Bengaluru\n"
     ]
    }
   ],
   "source": [
    "#as two of the job lies in other class extracting them using different loop\n",
    "for i in url_list[0:11]:\n",
    "    driver.get(i)\n",
    "    for k in driver.find_elements_by_xpath(\"//span[@class='slide-meta-loc pull-left']\"):\n",
    "        a=k.text\n",
    "        print(a)\n",
    "        Data_Job_Locations.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(Data_Job_Locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAIA-Center For Artificial Intelligence & Advanced Analytics\n",
      "\n",
      "Wrackle Technologies Pvt Ltd\n",
      "\n",
      "Altimetrik India Pvt. Ltd\n",
      "\n",
      "Bristlecone India Limited\n",
      "\n",
      "Dell International Services IndiaPrivate Limited\n",
      "\n",
      "Philips Lighting\n",
      "\n",
      "Morgan Stanley Advantage Services\n",
      "\n",
      "Philips Lighting\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extracting the Comapny_name web element from the webpage\n",
    "for i in url_list[0:11]:\n",
    "    driver.get(i)\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\"):\n",
    "        a=j.text\n",
    "        print(a)\n",
    "        Data_Company_name.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlaxoSmithKline Pharmaceuticals Limited\n",
      "Mphasis Limited\n"
     ]
    }
   ],
   "source": [
    "#as two of the job lies in other class extracting them using different loop\n",
    "for i in url_list[0:11]:\n",
    "    driver.get(i)\n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='cpName f14']\"):\n",
    "        a=k.text\n",
    "        print(a)\n",
    "        Data_Company_name.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(Data_Company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the first job Job_description web element from the webpage\n",
    "for i in url_list[0:11]:\n",
    "    driver.get(i)\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='dang-inner-html']\"):\n",
    "        a=j.text\n",
    "        Data_Job_description.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as two of the job lies in other class extracting them using different loop\n",
    "for i in url_list[0:11]:\n",
    "    driver.get(i)\n",
    "    for k in driver.find_elements_by_xpath(\"//div[@class='clearboth description']\"):\n",
    "        a=k.text\n",
    "        Data_Job_description.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(Data_Job_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crating a dataframe to store Job details\n",
    "scientist_df=pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the job details in data frame\n",
    "scientist_df['Company_name']=Data_Company_name\n",
    "scientist_df['Job Titles']=Data_Job_titles\n",
    "scientist_df['Loaction']=Data_Job_Locations\n",
    "scientist_df['Job Description']=Data_Job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>Loaction</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAIA-Center For Artificial Intelligence &amp; Adva...</td>\n",
       "      <td>Immediate opening For Data Scientist/Data Analyst</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>Dear Candidate\\n\\nSchedule a Telephonic Interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Roles and Responsibilities\\nRequirements :\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Altimetrik India Pvt. Ltd</td>\n",
       "      <td>Data Scientist / Data Analyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>3+ years of data science,\\ndata analytics, or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bristlecone India Limited</td>\n",
       "      <td>Explore job openings on Data Scientist!!</td>\n",
       "      <td>Pune, Mumbai, Bengaluru</td>\n",
       "      <td>JOB DESCRIPTION\\n\\nExp 4+ years\\n\\n1) Hands-on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell International Services IndiaPrivate Limited</td>\n",
       "      <td>Senior Principal Software Engineer - IT ( Data...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Key Responsibilities\\n\\nYou will be applying, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Philips Lighting</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>We re on the lookout for forward-thinking inno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Morgan Stanley Advantage Services</td>\n",
       "      <td>Machine Learning Lead / Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>The Technology &amp; Operations Risk (TOR) organiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Philips Lighting</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>We re looking for a Principal Data Scientist t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>GLOBAL MEDICAL DATA SCIENTIST</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Roles and Responsibilities\\nThe  Global (Medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mphasis Limited</td>\n",
       "      <td>ADVANCED ARCHITECT – DATA SCIENTIST</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job description\\nWe are looking for a Data Sci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Company_name  \\\n",
       "0  CAIA-Center For Artificial Intelligence & Adva...   \n",
       "1                       Wrackle Technologies Pvt Ltd   \n",
       "2                          Altimetrik India Pvt. Ltd   \n",
       "3                          Bristlecone India Limited   \n",
       "4   Dell International Services IndiaPrivate Limited   \n",
       "5                                   Philips Lighting   \n",
       "6                  Morgan Stanley Advantage Services   \n",
       "7                                   Philips Lighting   \n",
       "8            GlaxoSmithKline Pharmaceuticals Limited   \n",
       "9                                    Mphasis Limited   \n",
       "\n",
       "                                          Job Titles  \\\n",
       "0  Immediate opening For Data Scientist/Data Analyst   \n",
       "1  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "2                      Data Scientist / Data Analyst   \n",
       "3           Explore job openings on Data Scientist!!   \n",
       "4  Senior Principal Software Engineer - IT ( Data...   \n",
       "5                              Senior Data Scientist   \n",
       "6             Machine Learning Lead / Data Scientist   \n",
       "7                           Principal Data Scientist   \n",
       "8                      GLOBAL MEDICAL DATA SCIENTIST   \n",
       "9                ADVANCED ARCHITECT – DATA SCIENTIST   \n",
       "\n",
       "                              Loaction  \\\n",
       "0  Chennai, Pune, Bengaluru, Hyderabad   \n",
       "1                            Bengaluru   \n",
       "2                            Bengaluru   \n",
       "3              Pune, Mumbai, Bengaluru   \n",
       "4                            Bengaluru   \n",
       "5                            Bengaluru   \n",
       "6                            Bengaluru   \n",
       "7                            Bengaluru   \n",
       "8                            Bengaluru   \n",
       "9                            Bengaluru   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Dear Candidate\\n\\nSchedule a Telephonic Interv...  \n",
       "1  Roles and Responsibilities\\nRequirements :\\n\\n...  \n",
       "2  3+ years of data science,\\ndata analytics, or ...  \n",
       "3  JOB DESCRIPTION\\n\\nExp 4+ years\\n\\n1) Hands-on...  \n",
       "4  Key Responsibilities\\n\\nYou will be applying, ...  \n",
       "5  We re on the lookout for forward-thinking inno...  \n",
       "6  The Technology & Operations Risk (TOR) organiz...  \n",
       "7  We re looking for a Principal Data Scientist t...  \n",
       "8  Roles and Responsibilities\\nThe  Global (Medic...  \n",
       "9  Job description\\nWe are looking for a Data Sci...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scientist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-3-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to web driver\n",
    "driver=webdriver.Chrome(r\"C:/Users/Akshai/Downloads/chromedriver_win32 (1)/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_3=\"https://www.naukri.com/data-scientist-jobs-in-delhi-ncr?k=data%20scientist&l=delhi%2Fncr&cityType=25.9.31&ctcFilter=3to6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delhi_Job_titles=[]\n",
    "Delhi_Job_Locations=[]\n",
    "Delhi_Company_name=[]\n",
    "Delhi_experince_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the Job title web element from the webpage\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the first 10 jobs title \n",
    "n_titles=titles[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tech Mahindra Hiring For Data Scientist- Hyderabad/ Noida\n",
      "Data Scientist - Python/Machine Learning\n",
      "Data Scientist\n",
      "Only Fresher / Data Scientist / Data Analyst / Business Analytics- MNC\n",
      "Only Fresher / Data Scientist / Data Analyst / Business Analytics- MNC\n",
      "Data Scientist\n",
      "Lead Data Scientist\n",
      "Excellent opportunity For Lead Data Scientist at Noida location\n",
      "Lead Data Scientist\n",
      "Excellent opportunity For Lead Data Scientist at Noida location\n"
     ]
    }
   ],
   "source": [
    "#as we have saved the web element above from which we want to scrape the job title\n",
    "\n",
    "#implementing the loop to the web element extracted above and taking out the text present in it\n",
    "for i in n_titles:\n",
    "    title=i.text\n",
    "    print(title)\n",
    "    Delhi_Job_titles.append(title)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(Delhi_Job_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the Location web element from the webpage\n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the first 10 jobs location title \n",
    "n_location=location[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we have saved the web element above from which we want to scrape the job Location\n",
    "\n",
    "#implementing the loop to the web element extracted above and taking out the text present in it\n",
    "for i in n_location:\n",
    "    locate=i.text\n",
    "    Delhi_Job_Locations.append(locate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(Delhi_Job_Locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the Comapny_Name web element from the webpage\n",
    "co_name=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the first 10 Company name \n",
    "n_name=co_name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we have saved the web element above from which we want to scrape the Company name\n",
    "\n",
    "#implementing the loop to the web element extracted above and taking out the text present in it\n",
    "for i in n_name:\n",
    "    name_=i.text\n",
    "    Delhi_Company_name.append(name_)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(Delhi_Company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the Experience web element from the webpage\n",
    "exp=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the first 10 Experince list\n",
    "n_exp=exp[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we have saved the web element above from which we want to scrape the Experience\n",
    "\n",
    "#implementing the loop to the web element extracted above and taking out the text present in it\n",
    "for i in n_exp:\n",
    "    exp_=i.text\n",
    "    Delhi_experince_list.append(exp_)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delhi_job_df=pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delhi_job_df['Job_Title']=Delhi_Job_titles\n",
    "Delhi_job_df['Comapny_Name']=Delhi_Company_name\n",
    "Delhi_job_df['Location']=Delhi_Job_Locations\n",
    "Delhi_job_df['Experience']= Delhi_experince_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Comapny_Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tech Mahindra Hiring For Data Scientist- Hyder...</td>\n",
       "      <td>tech mahindra ltd</td>\n",
       "      <td>Hyderabad, Noida</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Python/Machine Learning</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>Noida</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Delhi NCR, Noida, Gurgaon</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>Delhi NCR, Greater Noida, Noida</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Air Asia India Limited</td>\n",
       "      <td>Delhi NCR, Gurgaon</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>Delhi NCR, Noida(Sector-142 Noida)</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Excellent opportunity For Lead Data Scientist ...</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>Delhi NCR(Sector-142 Noida), Noida</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>Delhi NCR, Noida(Sector-142 Noida)</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Excellent opportunity For Lead Data Scientist ...</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LTD</td>\n",
       "      <td>Delhi NCR(Sector-142 Noida), Noida</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0  Tech Mahindra Hiring For Data Scientist- Hyder...   \n",
       "1           Data Scientist - Python/Machine Learning   \n",
       "2                                     Data Scientist   \n",
       "3  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "4  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "5                                     Data Scientist   \n",
       "6                                Lead Data Scientist   \n",
       "7  Excellent opportunity For Lead Data Scientist ...   \n",
       "8                                Lead Data Scientist   \n",
       "9  Excellent opportunity For Lead Data Scientist ...   \n",
       "\n",
       "                        Comapny_Name                            Location  \\\n",
       "0                  tech mahindra ltd                    Hyderabad, Noida   \n",
       "1                              Jubna                               Noida   \n",
       "2             IBM India Pvt. Limited                    Gurgaon Gurugram   \n",
       "3          GABA Consultancy services           Delhi NCR, Noida, Gurgaon   \n",
       "4          GABA Consultancy services     Delhi NCR, Greater Noida, Noida   \n",
       "5             Air Asia India Limited                  Delhi NCR, Gurgaon   \n",
       "6  NEC CORPORATION INDIA PRIVATE LTD  Delhi NCR, Noida(Sector-142 Noida)   \n",
       "7  NEC CORPORATION INDIA PRIVATE LTD  Delhi NCR(Sector-142 Noida), Noida   \n",
       "8  NEC CORPORATION INDIA PRIVATE LTD  Delhi NCR, Noida(Sector-142 Noida)   \n",
       "9  NEC CORPORATION INDIA PRIVATE LTD  Delhi NCR(Sector-142 Noida), Noida   \n",
       "\n",
       "  Experience  \n",
       "0    3-8 Yrs  \n",
       "1    5-8 Yrs  \n",
       "2    4-8 Yrs  \n",
       "3    0-0 Yrs  \n",
       "4    0-0 Yrs  \n",
       "5    1-4 Yrs  \n",
       "6   9-14 Yrs  \n",
       "7   9-14 Yrs  \n",
       "8   9-14 Yrs  \n",
       "9   9-14 Yrs  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Delhi_job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-4- Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to web driver\n",
    "driver=webdriver.Chrome(r\"C:/Users/Akshai/Downloads/chromedriver_win32 (1)/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_4=\"https://www.glassdoor.co.in/Job/noida-data-scientist-jobs-SRCH_IL.0,5_IC4477468_KO6,20.htm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "Company_name=[]\n",
    "Rating=[]\n",
    "Job_posted=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=driver.find_elements_by_xpath(\"//a[@class=' css-10l5u4p e1n63ojh0 jobLink']/span[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"119b80024d3bf6eb3ce7c5a1e728c4ea\", element=\"5da300f8-d263-43ab-b818-bcdc82f8ccbc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"119b80024d3bf6eb3ce7c5a1e728c4ea\", element=\"e2cc3067-f858-4324-8ac4-ccd60d0264ff\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"119b80024d3bf6eb3ce7c5a1e728c4ea\", element=\"18cf2c56-5a0d-4448-9990-22aae251d873\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"119b80024d3bf6eb3ce7c5a1e728c4ea\", element=\"539432bd-ee64-485b-b6ee-aeec6e9e1d7b\")>]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_=name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we have saved the web element above from which we want to scrape the job title\n",
    "\n",
    "#implementing the loop to the web element extracted above and taking out the text present in it\n",
    "for i in name_:\n",
    "    _name=i.text\n",
    "    Company_name.append(_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "days=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_days=days[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we have saved the web element above from which we want to scrape the job title\n",
    "\n",
    "#implementing the loop to the web element extracted above and taking out the text present in it\n",
    "for i in n_days:\n",
    "    _days=i.text\n",
    "    Job_posted.append(_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate=driver.find_elements_by_xpath(\"//div[@class='d-flex flex-column css-fbt9gv e1rrn5ka2']/span[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"119b80024d3bf6eb3ce7c5a1e728c4ea\", element=\"daa538ad-cccf-4350-aff6-a6e853f74981\")>]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rate=rate[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3.8\n",
      "4.3\n",
      "3.4\n",
      "3.7\n",
      "4\n",
      "3.6\n",
      "3.8\n",
      "5\n",
      "3.8\n"
     ]
    }
   ],
   "source": [
    "#as we have saved the web element above from which we want to scrape the job title\n",
    "\n",
    "#implementing the loop to the web element extracted above and taking out the text present in it\n",
    "for i in n_rate:\n",
    "    _days=i.text\n",
    "    print(_days)\n",
    "    Rating.append(_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Company_name),len(Job_posted),len(Rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "glassdoor_df=pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "glassdoor_df['Company_name']=Company_name\n",
    "glassdoor_df['Job_posted']=Job_posted\n",
    "glassdoor_df['Rating']=Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Job_posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM</td>\n",
       "      <td>24h</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>17d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>4d</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GroundTruth</td>\n",
       "      <td>5d</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brickred</td>\n",
       "      <td>8d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mahajan Imaging</td>\n",
       "      <td>17d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GLG</td>\n",
       "      <td>24d</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>17d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ANI Calls India Private Limited</td>\n",
       "      <td>6d</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>itForte</td>\n",
       "      <td>17d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Company_name Job_posted Rating\n",
       "0                              IBM        24h      4\n",
       "1                          Genpact        17d    3.8\n",
       "2                           Amazon         4d    4.3\n",
       "3                      GroundTruth         5d    3.4\n",
       "4                         Brickred         8d    3.7\n",
       "5                  Mahajan Imaging        17d      4\n",
       "6                              GLG        24d    3.6\n",
       "7                          Genpact        17d    3.8\n",
       "8  ANI Calls India Private Limited         6d      5\n",
       "9                          itForte        17d    3.8"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glassdoor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-5- Write a python program to scrape the salary data for Data Scientist designation in Noida location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to web driver\n",
    "driver=webdriver.Chrome(r\"C:/Users/Akshai/Downloads/chromedriver_win32 (1)/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_5=\"https://www.glassdoor.co.in/Salaries/new-delhi-data-scientist-salary-SRCH_IL.0,9_IM1083_KO10,24.htm?clickSource=searchBtn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "Company_name=[]\n",
    "min_salary=[]\n",
    "Avg_salary=[]\n",
    "max_salary=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "No_fo_salary=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_salary=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "_name=driver.find_elements_by_xpath(\"//p[@class='m-0']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"683a230999e70120e2f015addd1205f6\", element=\"d53f2388-8d1a-4793-961e-4a25de011892\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"683a230999e70120e2f015addd1205f6\", element=\"bcf4a1de-f7c5-4d3c-99f8-2171dff2782f\")>]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_name[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "_n_name=_name[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in _n_name:\n",
    "    name=i.text\n",
    "    Company_name.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Delhivery',\n",
       " 'See 13 salaries from all locations',\n",
       " 'Data Scientist',\n",
       " 'Accenture',\n",
       " 'See 31 salaries from all locations',\n",
       " 'Data Scientist',\n",
       " 'IBM',\n",
       " 'See 62 salaries from all locations',\n",
       " 'Data Scientist',\n",
       " 'Ericsson-Worldwide',\n",
       " 'See 18 salaries from all locations',\n",
       " 'Data Scientist',\n",
       " 'UnitedHealth Group',\n",
       " 'See 12 salaries from all locations',\n",
       " 'Data Scientist - Monthly Intern',\n",
       " 'Analytics Vidhya',\n",
       " 'See 8 salaries from all locations',\n",
       " 'Data Scientist',\n",
       " 'Tata Consultancy Services',\n",
       " 'See 69 salaries from all locations',\n",
       " 'Data Scientist',\n",
       " 'Cognizant Technology Solutions',\n",
       " 'See 40 salaries from all locations',\n",
       " 'Data Scientist',\n",
       " 'Valiance Solutions',\n",
       " 'See 10 salaries from all locations',\n",
       " 'Data Scientist - Monthly Intern',\n",
       " 'Vidooly Media Tech',\n",
       " 'See 10 salaries from all locations']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'See 10 salaries from all locations'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As there are three web element with same tag and class name poping unwanted element out\n",
    "Company_name.pop(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_sal=driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"683a230999e70120e2f015addd1205f6\", element=\"f2a88a05-afc5-4fbe-a0e1-570a45d71e19\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"683a230999e70120e2f015addd1205f6\", element=\"083957eb-0ed5-4fac-bd05-80fdd42be54e\")>]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_sal[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sal=no_sal[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 salaries\n",
      "9 salaries\n",
      "7 salaries\n",
      "7 salaries\n",
      "7 salaries\n",
      "7 salaries\n",
      "6 salaries\n",
      "6 salaries\n",
      "6 salaries\n",
      "6 salaries\n"
     ]
    }
   ],
   "source": [
    "for i in n_sal:\n",
    "    sal=i.text\n",
    "    print(sal)\n",
    "    No_fo_salary.append(sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(No_fo_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sal=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container ']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sal=min_sal[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "₹705K\n",
      "₹11,495K\n",
      "₹571K\n",
      "₹2,200K\n",
      "₹580K\n",
      "₹2,700K\n",
      "₹468K\n",
      "₹1,595K\n",
      "₹708K\n",
      "₹1,557K\n",
      "₹14K\n",
      "₹22K\n",
      "₹488K\n",
      "₹1,000K\n",
      "₹784K\n",
      "₹1,250K\n",
      "₹496K\n",
      "₹1,138K\n",
      "₹8K\n",
      "₹20K\n"
     ]
    }
   ],
   "source": [
    "for i in n_sal:\n",
    "    sal=i.text\n",
    "    print(sal)\n",
    "    min_max_salary.append(sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sal=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"683a230999e70120e2f015addd1205f6\", element=\"de3db59e-9dac-488d-a7bc-79c6c1ecd615\")>]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_sal[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sal=a_sal[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "₹ 12,83,026\n",
      "₹ 11,19,272\n",
      "₹ 7,52,445\n",
      "₹ 8,28,000\n",
      "₹ 13,21,601\n",
      "₹ 20,889\n",
      "₹ 6,33,432\n",
      "₹ 9,96,446\n",
      "₹ 7,71,320\n",
      "₹ 12,669\n"
     ]
    }
   ],
   "source": [
    "for i in n_sal:\n",
    "    sal=i.text\n",
    "    print(sal)\n",
    "    Avg_salary.append(sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "Salary_df=pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "Salary_df[\"Company_Nmae\"]=Company_name\n",
    "Salary_df[\"No_of_Salaries\"]=No_fo_salary\n",
    "Salary_df[\"Min-Max_Salary\"]=min_max_salary\n",
    "Salary_df[\"Average_Salary\"]=Avg_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Nmae</th>\n",
       "      <th>No_of_Salaries</th>\n",
       "      <th>Min-Max_Salary</th>\n",
       "      <th>Average_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>12 salaries</td>\n",
       "      <td>₹705K\\n₹11,495K</td>\n",
       "      <td>₹ 12,83,026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹571K\\n₹2,200K</td>\n",
       "      <td>₹ 11,19,272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹580K\\n₹2,700K</td>\n",
       "      <td>₹ 7,52,445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹468K\\n₹1,595K</td>\n",
       "      <td>₹ 8,28,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹708K\\n₹1,557K</td>\n",
       "      <td>₹ 13,21,601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analytics Vidhya</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹14K\\n₹22K</td>\n",
       "      <td>₹ 20,889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹488K\\n₹1,000K</td>\n",
       "      <td>₹ 6,33,432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹784K\\n₹1,250K</td>\n",
       "      <td>₹ 9,96,446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹496K\\n₹1,138K</td>\n",
       "      <td>₹ 7,71,320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vidooly Media Tech</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹8K\\n₹20K</td>\n",
       "      <td>₹ 12,669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company_Nmae No_of_Salaries   Min-Max_Salary  \\\n",
       "0                       Delhivery    12 salaries  ₹705K\\n₹11,495K   \n",
       "1                       Accenture     9 salaries   ₹571K\\n₹2,200K   \n",
       "2                             IBM     7 salaries   ₹580K\\n₹2,700K   \n",
       "3              Ericsson-Worldwide     7 salaries   ₹468K\\n₹1,595K   \n",
       "4              UnitedHealth Group     7 salaries   ₹708K\\n₹1,557K   \n",
       "5                Analytics Vidhya     7 salaries       ₹14K\\n₹22K   \n",
       "6       Tata Consultancy Services     6 salaries   ₹488K\\n₹1,000K   \n",
       "7  Cognizant Technology Solutions     6 salaries   ₹784K\\n₹1,250K   \n",
       "8              Valiance Solutions     6 salaries   ₹496K\\n₹1,138K   \n",
       "9              Vidooly Media Tech     6 salaries        ₹8K\\n₹20K   \n",
       "\n",
       "  Average_Salary  \n",
       "0    ₹ 12,83,026  \n",
       "1    ₹ 11,19,272  \n",
       "2     ₹ 7,52,445  \n",
       "3     ₹ 8,28,000  \n",
       "4    ₹ 13,21,601  \n",
       "5       ₹ 20,889  \n",
       "6     ₹ 6,33,432  \n",
       "7     ₹ 9,96,446  \n",
       "8     ₹ 7,71,320  \n",
       "9       ₹ 12,669  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Salary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-6-Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: 1. Brand 2. Product Description 3. Price 4. Discount % "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to web driver\n",
    "driver=webdriver.Chrome(r\"C:/Users/Akshai/Downloads/chromedriver_win32 (1)/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_6=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_6.append(\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_6.append(\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=2\")\n",
    "url_6.append(\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand_name=[]\n",
    "Product_Description=[]\n",
    "Price=[]\n",
    "Discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url_6:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #extracting the brand_name web element from the webpage\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        brand=j.text\n",
    "        Brand_name.append(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Brand_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_name=Brand_name[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarized Aviator Sunglasses (58)\n",
      "UV Protection, Mirrored Retro Square Sunglasses (53)\n",
      "UV Protection Round Sunglasses (Free Size)\n",
      "UV Protection Retro Square Sunglasses (Free Size)\n",
      "Gradient, Mirrored, UV Protection, Polarized Round, Rou...\n",
      "UV Protection Retro Square Sunglasses (Free Size)\n",
      "Polarized Aviator Sunglasses (54)\n",
      "Gradient, Mirrored, UV Protection Round, Round, Round S...\n",
      "Gradient, Mirrored, UV Protection Aviator Sunglasses (F...\n",
      "Gradient, UV Protection Wayfarer Sunglasses (Free Size)\n",
      "Polarized Sports Sunglasses (68)\n",
      "Mirrored Aviator Sunglasses (Free Size)\n",
      "Polarized, UV Protection, Gradient Rectangular Sunglass...\n",
      "UV Protection Rectangular Sunglasses (Free Size)\n",
      "Night Vision, UV Protection Rectangular Sunglasses (45)\n",
      "UV Protection, Riding Glasses Rectangular Sunglasses (F...\n",
      "UV Protection, Gradient Rectangular Sunglasses (Free Si...\n",
      "UV Protection Spectacle Sunglasses (Free Size)\n",
      "UV Protection Over-sized Sunglasses (60)\n",
      "UV Protection Aviator Sunglasses (54)\n",
      "UV Protection Wayfarer, Sports, Shield, Rectangular, Re...\n",
      "UV Protection, Polarized Aviator Sunglasses (Free Size)\n",
      "Polarized Sports Sunglasses (65)\n",
      "UV Protection Wayfarer Sunglasses (Free Size)\n",
      "UV Protection Aviator Sunglasses (58)\n",
      "UV Protection Aviator Sunglasses (Free Size)\n",
      "UV Protection, Riding Glasses, Night Vision Sports Sung...\n",
      "Riding Glasses, UV Protection Oval Sunglasses (52)\n",
      "UV Protection Wayfarer Sunglasses (Free Size)\n",
      "Mirrored Aviator Sunglasses (55)\n",
      "Polarized, UV Protection, Gradient Aviator Sunglasses (...\n",
      "Gradient Spectacle Sunglasses (Free Size)\n",
      "UV Protection, Polarized Round Sunglasses (Free Size)\n",
      "UV Protection Round Sunglasses (Free Size)\n",
      "Mirrored Wayfarer Sunglasses (Free Size)\n",
      "UV Protection Aviator Sunglasses (Free Size)\n",
      "UV Protection Aviator Sunglasses (55)\n",
      "Polarized Aviator Sunglasses (58)\n",
      "UV Protection Retro Square Sunglasses (Free Size)\n",
      "UV Protection Rectangular Sunglasses (60)\n",
      "UV Protection Aviator Sunglasses (54)\n",
      "Polarized Aviator Sunglasses (54)\n",
      "UV Protection Wayfarer Sunglasses (56)\n",
      "UV Protection Wayfarer Sunglasses (Free Size)\n",
      "UV Protection Aviator Sunglasses (Free Size)\n",
      "UV Protection Aviator Sunglasses (54)\n",
      "UV Protection, Gradient Wayfarer Sunglasses (55)\n",
      "UV Protection Over-sized Sunglasses (60)\n",
      "Mirrored Round Sunglasses (53)\n",
      "UV Protection, Mirrored Retro Square Sunglasses (53)\n",
      "Polarized Sports Sunglasses (68)\n",
      "Gradient, UV Protection Aviator Sunglasses (99)\n",
      "UV Protection Round, Oval, Spectacle , Clubmaster, Wayf...\n",
      "UV Protection Wayfarer Sunglasses (Free Size)\n",
      "Night Vision, UV Protection Rectangular Sunglasses (45)\n",
      "Mirrored, UV Protection Retro Square Sunglasses (Free S...\n",
      "UV Protection Wayfarer Sunglasses (Free Size)\n",
      "UV Protection, Polarized Retro Square Sunglasses (59)\n",
      "UV Protection, Riding Glasses, Night Vision Sports Sung...\n",
      "UV Protection, Others Aviator Sunglasses (Free Size)\n",
      "UV Protection Aviator Sunglasses (53)\n",
      "UV Protection Wayfarer Sunglasses (32)\n",
      "UV Protection Spectacle Sunglasses (Free Size)\n",
      "Polarized Sports Sunglasses (65)\n",
      "UV Protection Round Sunglasses (54)\n",
      "UV Protection Retro Square Sunglasses (Free Size)\n",
      "UV Protection Round Sunglasses (54)\n",
      "UV Protection Wayfarer Sunglasses (Free Size)\n",
      "Polarized Aviator Sunglasses (58)\n",
      "UV Protection Oval Sunglasses (56)\n",
      "Polarized Aviator Sunglasses (54)\n",
      "UV Protection, Mirrored Clubmaster Sunglasses (Free Siz...\n",
      "UV Protection Round Sunglasses (Free Size)\n",
      "UV Protection, Polarized Aviator Sunglasses (Free Size)\n",
      "UV Protection, Polarized, Gradient Rectangular, Retro S...\n",
      "Gradient, UV Protection Round, Round Sunglasses (20)\n",
      "UV Protection Over-sized Sunglasses (60)\n",
      "UV Protection Wayfarer Sunglasses (55)\n",
      "UV Protection Round Sunglasses (Free Size)\n",
      "Riding Glasses, Night Vision Wrap-around Sunglasses (Fr...\n",
      "UV Protection Retro Square Sunglasses (Free Size)\n",
      "Polarized Sports Sunglasses (68)\n",
      "Mirrored Round Sunglasses (Free Size)\n",
      "UV Protection Aviator Sunglasses (57)\n",
      "Night Vision, UV Protection Rectangular Sunglasses (45)\n",
      "UV Protection Retro Square Sunglasses (Free Size)\n",
      "Polarized, UV Protection Aviator Sunglasses (Free Size)\n",
      "Polarized, UV Protection Retro Square Sunglasses (53)\n",
      "Polarized Sports Sunglasses (65)\n"
     ]
    }
   ],
   "source": [
    "for i in url_6:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #extracting the product_description web element from the webpage\n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\"):\n",
    "        pro=j.text\n",
    "        print(pro)\n",
    "        Product_Description.append(pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url_6:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #extracting the price web element from the webpage\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        pric=j.text\n",
    "        Price.append(pric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price=Price[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url_6:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #extracting the discount web element from the webpage\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span[1]\"):\n",
    "        dis=j.text\n",
    "        Discount.append(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "Discount=Discount[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    " Product_Description= Product_Description[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sunglasses_df=pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sunglasses_df['Brand']=b_name\n",
    "Sunglasses_df['Description']=Product_Description\n",
    "Sunglasses_df['Price']=Price\n",
    "Sunglasses_df['Discount']=Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Royal Son</td>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Royal Son</td>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹711</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹331</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trendy Glasses</td>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹236</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The Blue Pink</td>\n",
       "      <td>Polarized Aviator Sunglasses (54)</td>\n",
       "      <td>₹119</td>\n",
       "      <td>48% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Round, Round...</td>\n",
       "      <td>₹331</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>MAXX</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Aviator Sung...</td>\n",
       "      <td>₹215</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>like future</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹229</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Specsmakers</td>\n",
       "      <td>Polarized Sports Sunglasses (68)</td>\n",
       "      <td>₹569</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                                        Description Price  \\\n",
       "0          Royal Son                                          ROYAL SON  ₹664   \n",
       "1          Royal Son                                          ROYAL SON  ₹711   \n",
       "2         Phenomenal                                          ROYAL SON  ₹399   \n",
       "3   shah collections                                          ROYAL SON  ₹331   \n",
       "4     Trendy Glasses                                          ROYAL SON  ₹236   \n",
       "..               ...                                                ...   ...   \n",
       "95     The Blue Pink                  Polarized Aviator Sunglasses (54)  ₹119   \n",
       "96  shah collections  Gradient, Mirrored, UV Protection Round, Round...  ₹331   \n",
       "97              MAXX  Gradient, Mirrored, UV Protection Aviator Sung...  ₹215   \n",
       "98       like future  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹229   \n",
       "99       Specsmakers                   Polarized Sports Sunglasses (68)  ₹569   \n",
       "\n",
       "   Discount  \n",
       "0   66% off  \n",
       "1   64% off  \n",
       "2   80% off  \n",
       "3   80% off  \n",
       "4   81% off  \n",
       "..      ...  \n",
       "95  48% off  \n",
       "96  80% off  \n",
       "97  79% off  \n",
       "98  82% off  \n",
       "99  71% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sunglasses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-7- Scrape 100 reviews data from flipkart.com for iphone11 phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to web driver\n",
    "driver=webdriver.Chrome(r\"C:/Users/Akshai/Downloads/chromedriver_win32 (1)/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_7=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_7.append(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\")\n",
    "url_7.append(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=2\")\n",
    "url_7.append(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=3\")\n",
    "url_7.append(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=4\")\n",
    "url_7.append(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=5\")\n",
    "url_7.append(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=6\")\n",
    "url_7.append(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=7\")\n",
    "url_7.append(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=8\")\n",
    "url_7.append(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=9\")\n",
    "url_7.append(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&page=10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings=[]\n",
    "Review_Summary=[]\n",
    "Full_Review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url_7:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #extracting the rating  web element from the webpage\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        rate=j.text\n",
    "        Ratings.append(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url_7:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #extracting the Full_summary web element from the webpage\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "        R_S=j.text\n",
    "        Review_Summary.append(R_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Review_Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url_7:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #extracting the Review_summary web element from the webpage\n",
    "    for j in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        R_S=j.text\n",
    "        Full_Review.append(R_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Full_Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iphone_review_df=pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iphone_review_df['Ratings']=Ratings\n",
    "Iphone_review_df['Review_Summary']=Full_Review\n",
    "Iphone_review_df['Full_Review']=Review_Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review_Summary</th>\n",
       "      <th>Full_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Iphone 11 black 64gb is really a cool phone\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Nice</td>\n",
       "      <td>Although it’s an iPhone, it doesn’t give anyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Apple i Phone is the best phone available in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>use outside gives a outstanding experience ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Delightful</td>\n",
       "      <td>Just the display held it from being a 5star ph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings      Review_Summary  \\\n",
       "0        5    Perfect product!   \n",
       "1        5       Great product   \n",
       "2        5    Perfect product!   \n",
       "3        5  Highly recommended   \n",
       "4        5    Perfect product!   \n",
       "..     ...                 ...   \n",
       "95       3                Nice   \n",
       "96       5                Nice   \n",
       "97       5           Just wow!   \n",
       "98       4           Brilliant   \n",
       "99       4          Delightful   \n",
       "\n",
       "                                          Full_Review  \n",
       "0   Amazing phone with great cameras and better ba...  \n",
       "1   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "2   It’s a must buy who is looking for an upgrade ...  \n",
       "3   iphone 11 is a very good phone to buy only if ...  \n",
       "4   Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "..                                                ...  \n",
       "95  Iphone 11 black 64gb is really a cool phone\\n\\...  \n",
       "96  Although it’s an iPhone, it doesn’t give anyth...  \n",
       "97  Apple i Phone is the best phone available in t...  \n",
       "98  use outside gives a outstanding experience ......  \n",
       "99  Just the display held it from being a 5star ph...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Iphone_review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-8-Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to web driver\n",
    "driver=webdriver.Chrome(r\"C:/Users/Akshai/Downloads/chromedriver_win32 (1)/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_8=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_8.append(\"https://www.flipkart.com/search?q=sneakers&sid=osp%2Ccil%2Ce1f&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_1_4_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_4_na_na_na&as-pos=1&as-type=RECENT&suggestionId=sneakers%7CMen%27s+Casual+Shoes&requestId=bad2edc3-6996-451a-b1af-b73cecba0b61&as-searchtext=snea\")\n",
    "url_8.append(\"https://www.flipkart.com/search?q=sneakers&sid=osp%2Ccil%2Ce1f&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_1_4_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_4_na_na_na&as-pos=1&as-type=RECENT&suggestionId=sneakers%7CMen%27s+Casual+Shoes&requestId=bad2edc3-6996-451a-b1af-b73cecba0b61&as-searchtext=snea&page=2\")\n",
    "url_8.append(\"https://www.flipkart.com/search?q=sneakers&sid=osp%2Ccil%2Ce1f&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_1_4_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_4_na_na_na&as-pos=1&as-type=RECENT&suggestionId=sneakers%7CMen%27s+Casual+Shoes&requestId=bad2edc3-6996-451a-b1af-b73cecba0b61&as-searchtext=snea&page=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sneak_Brand_name=[]\n",
    "Sneak_Product_Description=[]\n",
    "Sneak_Price=[]\n",
    "Sneak_Discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url_8:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #extracting the Brand_Name web element from the webpage\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\"):\n",
    "        R_S=j.text\n",
    "        Sneak_Brand_name.append(R_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Sneak_Brand_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url_8:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #extracting the Brand_name web element from the webpage\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_2B099V']//a[1]\"):\n",
    "        p_d=j.text\n",
    "        Sneak_Product_Description.append(p_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Sneak_Product_Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url_8:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #extracting the Brand_name web element from the webpage\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\"):\n",
    "        pric=j.text\n",
    "        Sneak_Price.append(pric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Sneak_Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url_8:\n",
    "    driver.get(i)\n",
    "    \n",
    "    #extracting the Brand_name web element from the webpage\n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\"):\n",
    "        dis=j.text\n",
    "        Sneak_Discount.append(dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Sneak_Discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sneak_Brand_name=Sneak_Brand_name[0:100]\n",
    "Sneak_Product_Description=Sneak_Product_Description[0:100]\n",
    "Sneak_Price=Sneak_Price[0:100]\n",
    "Sneak_Discount=Sneak_Discount[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sneakers_df=pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sneakers_df['Brand_Name']=Sneak_Brand_name\n",
    "Sneakers_df['_Product_Description']=Sneak_Product_Description\n",
    "Sneakers_df['Price']=Sneak_Price=Sneak_Price\n",
    "Sneakers_df['Discount']=Sneak_Discount=Sneak_Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_Name</th>\n",
       "      <th>_Product_Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rockfield</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹426</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹579</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>171 Smart Tan Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹273</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Aura</td>\n",
       "      <td>Combo Pack of 5 Casual Shoes Sneakers, Loafers...</td>\n",
       "      <td>₹629</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Mercedes Drift Cat 8 Sneakers For Men</td>\n",
       "      <td>₹7,999</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Essence</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Rockfield</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>T-Rock</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand_Name                               _Product_Description   Price  \\\n",
       "0      Rockfield                                   Sneakers For Men    ₹426   \n",
       "1             TR                                   Sneakers For Men    ₹449   \n",
       "2         Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...    ₹579   \n",
       "3         Chevit  171 Smart Tan Lace-Ups Casuals for Men Sneaker...    ₹273   \n",
       "4   Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men    ₹399   \n",
       "..           ...                                                ...     ...   \n",
       "95          Aura  Combo Pack of 5 Casual Shoes Sneakers, Loafers...    ₹629   \n",
       "96          Puma              Mercedes Drift Cat 8 Sneakers For Men  ₹7,999   \n",
       "97       Essence                                   Sneakers For Men    ₹474   \n",
       "98     Rockfield                                   Sneakers For Men    ₹449   \n",
       "99        T-Rock                                   Sneakers For Men    ₹399   \n",
       "\n",
       "   Discount  \n",
       "0   57% off  \n",
       "1   77% off  \n",
       "2   70% off  \n",
       "3   45% off  \n",
       "4   60% off  \n",
       "..      ...  \n",
       "95  74% off  \n",
       "96  52% off  \n",
       "97  55% off  \n",
       "98  60% off  \n",
       "99  64% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sneakers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-9-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to web driver\n",
    "driver=webdriver.Chrome(r\"C:/Users/Akshai/Downloads/chromedriver_win32 (1)/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_9=\"https://www.myntra.com/shoes?plaEnabled=false&rf=Price%3A6619.0_13079.0_6619.0%20TO%2013079.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//div[@class='common-checkboxIndicator']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=driver.find_element_by_xpath(\"//li[@class='colour-listItem']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_09=\"https://www.myntra.com/shoes?plaEnabled=false&rf=Price%3A6619.0_13079.0_6619.0%20TO%2013079.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//li[@class='colour-listItem']/div[@class='common-checkboxIndicator']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.find_element_by_xpath(\"//div[@class='common-checkboxIndicator']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to web driver\n",
    "driver=webdriver.Chrome(r\"C:/Users/Akshai/Downloads/chromedriver_win32 (1)/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_10=\"https://www.amazon.com/s?k=laptop&rh=n%3A565108%2Cp_n_feature_four_browse-bin%3A2289792011&dc&qid=1607263085&rnid=676578011&ref=sr_nr_p_n_feature_four_browse-bin_22\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "Laptop_Brand_name=[]\n",
    "Laptop_Price=[]\n",
    "Laptop_Ratings=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_name=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acer Spin 5 Convertible Laptop, 13.5\" 2K 2256 x 1504 IPS Touch, 10th Gen Intel Core i7-1065G7, 16GB LPDDR4X, 512GB NVMe SSD, Wi-Fi 6, Backlit KB, FPR, Rechargeable Active Stylus, SP513-54N-74V2\n",
      "Dell G3 15 3500 15 Inch FHD with 144Hz Refresh Rate Gaming Laptop, Intel Core i7-10750H 10th Gen, 16GB DDR4 RAM, 512GB SSD, Nvidia Geforce RTX 2060 6GB GDDR6, Windows 10 Home Black\n",
      "Acer Spin 5 Convertible Laptop, 13.5\" 2K 2256 x 1504 IPS Touch, 10th Gen Intel Core i7-1065G7, 16GB LPDDR4X, 512GB NVMe SSD, Wi-Fi 6, Backlit KB, FPR, Rechargeable Active Stylus, SP513-54N-74V2\n",
      "LG Gram 2-in-1 Convertible Laptop: 14\" Full HD IPS Touchscreen Display, Intel 10th Gen Core i7-10510U CPU, 16GB RAM, 1TB (512GB x 2) M.2 MVMe SSD, Thunderbolt 3, 20.5 Hour Battery 14T90N (2020)\n",
      "Microsoft Surface Laptop 3 for Business Ultra-Thin 15” Touchscreen Laptop Black (Metal) - Intel 10th Gen Quad Core i7, 16GB RAM, 512GB SSD, Windows 10 Pro, 2019 Edition - Black(Metal)\n",
      "LG Gram Laptop - 14\" Full HD IPS Display, Intel 10th Gen Core i7-1065G7 CPU, 16GB RAM, 512GB M.2 MVMe SSD, Thunderbolt 3, 18.5 Hour Battery Life - 14Z90N (2020)\n",
      "2020 Asus VivoBook 15 Thin & Light Laptop: 10th Gen Core i7-1065G7, 256GB SSD, 8GB RAM, 15.6\" Full HD Display, Backlit Keyboard, Windows 10\n",
      "LG Ultra PC High Performance Laptop - 17\" IPS WQXGA (2560 x 1600) Display and Intel 10th Generation Intel Core i7-10510U CPU, NVIDIA GTX1650 GDDR5 4GB, 16GB DDR4 2666 MHz RAM - 512GB NVMe SSD\n",
      "OEM Lenovo ThinkPad E15 15.6\" FHD Display 1920x1080 IPS, Intel Quad Core i7-10510U, 16GB RAM, 1TB SSD, W10P, Business Laptop\n",
      "HP 15-cs3019nr Pavilion 15.6-Inch Laptop, Intel Core i7 (Mineral Silver)\n"
     ]
    }
   ],
   "source": [
    "for i in lap_name[0:10]:\n",
    "    a=i.text\n",
    "    print(a)\n",
    "    Laptop_Brand_name.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Laptop_Brand_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_price=driver.find_elements_by_xpath(\"//a[@class='a-size-base a-link-normal a-text-normal']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$1,099\n",
      "99\n",
      "$1,300\n",
      "00\n",
      "$1,099\n",
      "99\n",
      "$2,499\n",
      "00\n",
      "$1,246\n",
      "99\n",
      "$1,599.99\n",
      "$633\n",
      "95\n",
      "$1,296\n",
      "99\n",
      "$1,699.99\n",
      "$1,179\n",
      "95\n",
      "$1,028\n",
      "00\n",
      "$1,757\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "for i in lap_price[0:10]:\n",
    "    a=i.text\n",
    "    print(a)\n",
    "    Laptop_Price.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Laptop_Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=requests.get(\"https://www.amazon.com/s?k=laptop&rh=n%3A565108%2Cp_n_feature_four_browse-bin%3A2289792011&dc&qid=1607263085&rnid=676578011&ref=sr_nr_p_n_feature_four_browse-bin_22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_rate=soup.find_all(\"a\",class_=\"a-popover-trigger a-declarative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lap_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lap_rate[0:10]:\n",
    "    a=i.text\n",
    "    print(a)\n",
    "    #Laptop_Ratings.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not able to fetch the rating as none of the tag is returning web element and \n",
    "on opening it in the new window it is showing the page is blocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "Laptop_df=pd.DataFrame({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "Laptop_df['Name']=Laptop_Brand_name\n",
    "Laptop_df['Price']=Laptop_Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Spin 5 Convertible Laptop, 13.5\" 2K 2256 ...</td>\n",
       "      <td>$1,099\\n99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell G3 15 3500 15 Inch FHD with 144Hz Refresh...</td>\n",
       "      <td>$1,300\\n00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer Spin 5 Convertible Laptop, 13.5\" 2K 2256 ...</td>\n",
       "      <td>$1,099\\n99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG Gram 2-in-1 Convertible Laptop: 14\" Full HD...</td>\n",
       "      <td>$2,499\\n00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Microsoft Surface Laptop 3 for Business Ultra-...</td>\n",
       "      <td>$1,246\\n99\\n$1,599.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LG Gram Laptop - 14\" Full HD IPS Display, Inte...</td>\n",
       "      <td>$633\\n95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020 Asus VivoBook 15 Thin &amp; Light Laptop: 10t...</td>\n",
       "      <td>$1,296\\n99\\n$1,699.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LG Ultra PC High Performance Laptop - 17\" IPS ...</td>\n",
       "      <td>$1,179\\n95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OEM Lenovo ThinkPad E15 15.6\" FHD Display 1920...</td>\n",
       "      <td>$1,028\\n00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP 15-cs3019nr Pavilion 15.6-Inch Laptop, Inte...</td>\n",
       "      <td>$1,757\\n51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name                  Price\n",
       "0  Acer Spin 5 Convertible Laptop, 13.5\" 2K 2256 ...             $1,099\\n99\n",
       "1  Dell G3 15 3500 15 Inch FHD with 144Hz Refresh...             $1,300\\n00\n",
       "2  Acer Spin 5 Convertible Laptop, 13.5\" 2K 2256 ...             $1,099\\n99\n",
       "3  LG Gram 2-in-1 Convertible Laptop: 14\" Full HD...             $2,499\\n00\n",
       "4  Microsoft Surface Laptop 3 for Business Ultra-...  $1,246\\n99\\n$1,599.99\n",
       "5  LG Gram Laptop - 14\" Full HD IPS Display, Inte...               $633\\n95\n",
       "6  2020 Asus VivoBook 15 Thin & Light Laptop: 10t...  $1,296\\n99\\n$1,699.99\n",
       "7  LG Ultra PC High Performance Laptop - 17\" IPS ...             $1,179\\n95\n",
       "8  OEM Lenovo ThinkPad E15 15.6\" FHD Display 1920...             $1,028\\n00\n",
       "9  HP 15-cs3019nr Pavilion 15.6-Inch Laptop, Inte...             $1,757\\n51"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Laptop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
